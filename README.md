
# UniT2IXL

<p align="center">
    <a href="https://huggingface.co/UnicomAI/UniT2IXL">Hugging Face</a>&nbsp;&nbsp;<a href="https://www.modelscope.cn/UnicomAI/UniT2IXL">ModelScope</a>&nbsp;&nbsp; <a href="https://www.wisemodel.cn/UnicomAI/UniT2IXL">WiseModel</a>
</p>

<figure>
  <img src="imgs/pic.png">
</figure>

<br>

## ğŸ“– ä»‹ç»
UniT2IXLæ˜¯ç”±ä¸­å›½è”é€šAIåˆ›æ–°ä¸­å¿ƒå›¢é˜Ÿå¼€å‘çš„ä¸€æ¬¾åŸºäºæ½œåœ¨æ‰©æ•£çš„å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹æ”¹è¿›äº†SDXLçš„ç¼–ç å™¨ï¼Œé‡‡ç”¨ä¸­æ–‡CLIPå®ç°å¯¹åŸç”Ÿä¸­æ–‡çš„æ”¯æŒï¼Œå¹¶å¼•å…¥mt5æ¶æ„æå‡å¯¹é•¿æ–‡æœ¬çš„ç†è§£èƒ½åŠ›ã€‚åœ¨å›½äº§æ˜‡è…¾AIåŸºç¡€è½¯ç¡¬ä»¶å¹³å°å®ç°äº†æ¨¡å‹ä»å¾®è°ƒè®­ç»ƒåˆ°æ¨ç†çš„ä¸€ä½“åŒ–é€‚é…
<p style="text-align: center;">
      <img src="imgs/unit2ixl.png" width="400"/>
</p>




## ğŸš€ å¿«é€Ÿå¼€å§‹
### ç¯å¢ƒä¾èµ–

* Python 3.8 or later
* PyTorch 2.4.0 or later
* Transformers 4.43.3 or later
* Diffusers 0.31.0
* Recommended: CUDA 11.7 or later
<br>

1. å¿«é€Ÿå®‰è£…

```bash
git clone https://github.com/UnicomAI/UniT2IXL.git
cd UniT2IXL
conda create -n unit2i python=3.10
conda activate unit2ixl
cd unit2ixl
pip install -r requirements.txt
```
2. æƒé‡ä¸‹è½½ï¼ˆ[link](https://huggingface.co/UnicomAI/UniT2IXL)ï¼‰ï¼š
```bash
huggingface-cli download --resume-download UnicomAI/UniT2IXL
```

3. æ¨ç†`demo.py`ï¼š
```bash
from pipline_unit2ixl import UniT2IXLPipeline
pipline = UniT2IXLPipeline.from_pretrained("UnicomAI/UniT2IXL")
pipline = pipline.to("cuda:0")
prompt = "åœ¨ç»¿è‰²çš„æ£®æ—ä¸­ï¼Œéšè—ç€ä¸€åº§ç™½è‰²çš„å“¥ç‰¹å¼æ•™å ‚ï¼Œæ•™å ‚çš„å°–å¡”ç›´æŒ‡è“è‰²çš„å¤©ç©ºï¼Œæ•™å ‚å‘¨å›´æ˜¯äº”å½©æ–‘æ–“çš„é‡èŠ±å’Œæµ…é»„è‰²çš„è‰åªã€‚"
image = pipline(prompt=prompt,guidance_scale=7.5,target_size=(1024,1024)).images[0]
```

# è®­ç»ƒ

æˆ‘ä»¬æä¾›è®­ç»ƒLoRAæ¨¡å‹ï¼Œä½¿ç”¨[DeepSpeed](https://github.com/microsoft/DeepSpeed)! æ”¯æŒ1024x1024åˆ†è¾¨ç‡

### å‡†å¤‡æ•°æ®
å‚è€ƒ[è¿™é‡Œ](https://huggingface.co/docs/datasets/image_dataset)
* æ•°æ®ç»“æ„

  ```
  folder/train/metadata.csv
  folder/train/0001.png
  folder/train/0002.png
  folder/train/0003.png
  ```
* å›¾åƒæ ‡æ³¨ metadata.csv:

  ```
  file_name,text
  0001.png,This is a golden retriever playing with a ball
  0002.png,A german shepherd
  0003.png,One chihuahua
  ```
  
### deepspeedé…ç½®æ ·ä¾‹
```
compute_environment: LOCAL_MACHINE
debug: true
deepspeed_config:
  deepspeed_multinode_launcher: standard
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  offload_optimizer_device: none
  offload_param_device: none
  zero3_init_flag: false
  zero_stage: 2
  train_micro_batch_size_per_gpu: 6
distributed_type: DEEPSPEED
downcast_bf16: 'no'
enable_cpu_affinity: false
machine_rank: 0
main_training_function: main
mixed_precision: 'no'
num_machines: 1
num_processes: 1
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

### Lora

```
export MODEL_NAME="UnicomAI/UniT2IXL"
export DATASET_NAME="lambdalabs/naruto-blip-captions"
export ACCELERATE_CONFIG_FILE="ac.yaml"
export CUDA_VISIBLE_DEVICES=0
accelerate launch --config_file $ACCELERATE_CONFIG_FILE  --main_process_port 12345 train_text_to_image_lora_unit2ixl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --caption_column="text" \
  --resolution=1024 --random_flip \
  --train_batch_size=4 \
  --num_train_epochs=200 --checkpointing_steps=1000 \
  --validation_epochs=10 \
  --learning_rate=1e-04 --lr_scheduler="constant" --lr_warmup_steps=0 \
  --seed=42 \
  --rank=8 \
  --output_dir="sd-papercut-model-lora-sdxl" \
  --validation_prompt="ä¸€ä¸ªé¾™çš„çª—èŠ±" \
  --noise_offset=0.1 \
  --dataset_name=$DATASET_NAME
```

## ğŸ’»UniT2IXL-NPU

æˆ‘ä»¬ä¹Ÿæä¾›äº†å¯ä»¥åœ¨NPUä¸Šè¿è¡ŒUniT2Içš„LoRAè®­ç»ƒä¸æ¨ç†ä»£ç ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[unit2ixl-npu](https://github.com/UnicomAI/UniT2IXL/blob/master/unit2ixl-npu/README.md)ã€‚


